{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('./Churn_Modelling.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 3:13]\n",
    "y = data.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.get_dummies(X['Geography'],drop_first=True)\n",
    "gen = pd.get_dummies(X['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42       2       0.00              1          1   \n",
      "1          608   41       1   83807.86              1          0   \n",
      "2          502   42       8  159660.80              3          1   \n",
      "3          699   39       1       0.00              2          0   \n",
      "4          850   43       2  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Male  Germany  Spain  \n",
      "0               1        101348.88     0        0      0  \n",
      "1               1        112542.58     0        0      1  \n",
      "2               0        113931.57     0        0      0  \n",
      "3               0         93826.63     0        0      0  \n",
      "4               1         79084.10     0        0      1  \n"
     ]
    }
   ],
   "source": [
    "Geography = geo.copy()\n",
    "Gender = gen.copy()\n",
    "\n",
    "X = X.drop(['Gender','Geography'], axis = 1)\n",
    "X = pd.concat([X,Gender, Geography],axis=1)\n",
    "\n",
    "print(X.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#Added input layer\n",
    "classifier.add(Dense(units=10, kernel_initializer = 'he_uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "#Adding Hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "#Adding Output Layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='Adamax', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5359 samples, validate on 2641 samples\n",
      "Epoch 1/100\n",
      "5359/5359 [==============================] - 2s 374us/step - loss: 0.9140 - accuracy: 0.5225 - val_loss: 0.5446 - val_accuracy: 0.7914\n",
      "Epoch 2/100\n",
      "5359/5359 [==============================] - 2s 338us/step - loss: 0.5052 - accuracy: 0.7966 - val_loss: 0.4987 - val_accuracy: 0.7948\n",
      "Epoch 3/100\n",
      "5359/5359 [==============================] - 2s 396us/step - loss: 0.4753 - accuracy: 0.7974 - val_loss: 0.4758 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "5359/5359 [==============================] - 2s 391us/step - loss: 0.4563 - accuracy: 0.7983 - val_loss: 0.4615 - val_accuracy: 0.7978\n",
      "Epoch 5/100\n",
      "5359/5359 [==============================] - 2s 400us/step - loss: 0.4426 - accuracy: 0.8057 - val_loss: 0.4517 - val_accuracy: 0.8001\n",
      "Epoch 6/100\n",
      "5359/5359 [==============================] - 2s 414us/step - loss: 0.4325 - accuracy: 0.8100 - val_loss: 0.4454 - val_accuracy: 0.8008\n",
      "Epoch 7/100\n",
      "5359/5359 [==============================] - 2s 421us/step - loss: 0.4252 - accuracy: 0.8141 - val_loss: 0.4417 - val_accuracy: 0.8012\n",
      "Epoch 8/100\n",
      "5359/5359 [==============================] - 2s 432us/step - loss: 0.4207 - accuracy: 0.8177 - val_loss: 0.4385 - val_accuracy: 0.8035\n",
      "Epoch 9/100\n",
      "5359/5359 [==============================] - 2s 428us/step - loss: 0.4173 - accuracy: 0.8184 - val_loss: 0.4364 - val_accuracy: 0.8035\n",
      "Epoch 10/100\n",
      "5359/5359 [==============================] - 2s 390us/step - loss: 0.4145 - accuracy: 0.8218 - val_loss: 0.4348 - val_accuracy: 0.8042\n",
      "Epoch 11/100\n",
      "5359/5359 [==============================] - 2s 358us/step - loss: 0.4123 - accuracy: 0.8252 - val_loss: 0.4332 - val_accuracy: 0.8080\n",
      "Epoch 12/100\n",
      "5359/5359 [==============================] - 2s 358us/step - loss: 0.4104 - accuracy: 0.8266 - val_loss: 0.4317 - val_accuracy: 0.8122\n",
      "Epoch 13/100\n",
      "5359/5359 [==============================] - 2s 355us/step - loss: 0.4089 - accuracy: 0.8265 - val_loss: 0.4305 - val_accuracy: 0.8118\n",
      "Epoch 14/100\n",
      "5320/5359 [============================>.] - ETA: 0s - loss: 0.4073 - accuracy: 0.8276"
     ]
    }
   ],
   "source": [
    "model_result = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"Score is : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Hyper Parameter Tuning\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(layers, activation):\n",
    "    model = Sequential()\n",
    "    for i, nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    model.compile(optimizer='Adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "batches = [128]\n",
    "epochs = [30]\n",
    "layers = [[20], [40,20], [45,30,15]]\n",
    "activations = ['sigmoid', 'relu']\n",
    "param_grid = dict(layers=layers, activation = activations, batch_size=batches, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commeneted out as it was performed\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = grid_result.best_score_\n",
    "best_param = grid_result.best_params_\n",
    "best_estimator = grid_result.best_estimator_\n",
    "\n",
    "print(\"Best Score After Hyper Paramter Tuning : \"+str(best_score))\n",
    "print(\"Best Parametres are : \"+str(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_classifier = Sequential()\n",
    "\n",
    "tuned_classifier.add(Dense(units=40, kernel_initializer='he_uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "tuned_classifier.add(Dropout(0.3))\n",
    "\n",
    "tuned_classifier.add(Dense(units=20, kernel_initializer = 'he_uniform', activation='relu'))\n",
    "tuned_classifier.add(Dropout(0.3))\n",
    "\n",
    "tuned_classifier.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "\n",
    "tuned_classifier.compile(optimizer='Adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_history = tuned_classifier.fit(X_train, y_train, validation_split=0.33, batch_size=128, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_score = accuracy_score(y_pred, y_test)\n",
    "print(\"Score after Tuning the model is : \"+str(tuned_score))\n",
    "\n",
    "filename = 'churn-model-85'\n",
    "import pickle\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "print(\"Model saved succesfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
